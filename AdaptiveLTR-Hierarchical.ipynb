{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: pyltr in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: scipy in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from pyltr) (1.3.1)\n",
      "Requirement already satisfied: pandas in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from pyltr) (0.25.0)\n",
      "Requirement already satisfied: numpy in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from pyltr) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from pyltr) (0.22)\n",
      "Requirement already satisfied: pytz>=2017.2 in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from pandas->pyltr) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from pandas->pyltr) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from scikit-learn->pyltr) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->pyltr) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: more_itertools in /miniconda3/envs/olp-sdk-for-python-0.6.0-env/lib/python3.7/site-packages (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pyltr\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "from more_itertools import sort_together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the key inside a dict\n",
    "def find_matching_key_index(id, data):\n",
    "    for i in range(0,len(data)):\n",
    "        if data[i]['id'] == id:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "## partition data cluster wise\n",
    "def partition_data_cluster_wise(X_d,Y_d,T_q,labels):\n",
    "    data_dict = []\n",
    "    for i in range(0, len(labels)):\n",
    "        idx = find_matching_key_index(labels[i],data_dict )\n",
    "        if idx == -1:\n",
    "            data = {}\n",
    "            data['id'] = labels[i]\n",
    "            data['data'] = X_d[i:i+1]\n",
    "            data['label'] = Y_d[i:i+1]\n",
    "            data['tqid'] = T_q[i:i+1]\n",
    "            data_dict.append(data)\n",
    "        else :\n",
    "            data = {}\n",
    "            d =  data_dict[idx]['data']\n",
    "            la =  data_dict[idx]['label']\n",
    "            tq =  data_dict[idx]['tqid']\n",
    "            data_dict[idx]['data'] = np.concatenate((d, X_d[i:i+1]), axis=0)\n",
    "            data_dict[idx]['label'] = np.concatenate((la, Y_d[i:i+1]), axis=0)\n",
    "            data_dict[idx]['tqid'] = np.concatenate((tq, T_q[i:i+1]), axis=0)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "## concatenate all the evaluation across clusters\n",
    "def concatenate_cluster_eval(p_data):\n",
    "    m_data = {}\n",
    "    m_data['data'] = np.array([[np.array(xx)] for xx in  p_data[0]['eval']])\n",
    "    m_data['label'] = p_data[0]['label']\n",
    "    m_data['tqid'] = p_data[0]['tqid']\n",
    "    for j in range(1, len(p_data)):\n",
    "        dd = np.array([[np.array(xx)] for xx in  p_data[j]['eval']])\n",
    "        m_data['data'] = np.concatenate((m_data['data'] ,dd), axis=0)\n",
    "        m_data['label'] = np.concatenate((m_data['label'] , p_data[j]['label']), axis=0)\n",
    "        m_data['tqid'] = np.concatenate((m_data['tqid'] , p_data[j]['tqid']), axis=0)\n",
    "    return m_data\n",
    "\n",
    "## train model using LamdaMart \n",
    "def train_model_using_LambdaMART(p_data):\n",
    "    for j in range(0,len(p_data)):\n",
    "        metric = pyltr.metrics.NDCG(k=5)\n",
    "    \n",
    "        model = pyltr.models.LambdaMART(\n",
    "            metric=metric,\n",
    "            n_estimators=500,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        model.fit(p_data[j]['data'], p_data[j]['label'], p_data[j]['tqid'])\n",
    "        p_data[j]['model'] = model\n",
    "        p_data[j]['metric'] = metric\n",
    "      \n",
    "    return p_data\n",
    "\n",
    "##evaluate partiotioned data\n",
    "def evaluate_partitioned_data(p_data) :\n",
    "    for j in range(0,len(p_data)):\n",
    "        Epred = p_data[j]['model'].predict(p_data[j]['data'])\n",
    "        evl_arr = evalute_preds(p_data[j]['label'],Epred,p_data[j]['tqid'], p_data[j]['metric'])\n",
    "        p_data[j]['eval'] = evl_arr\n",
    "    return p_data\n",
    "\n",
    "##evaluate on all features\n",
    "def evaluate_features(p_data, X, Y, tqids):\n",
    "    eval_dict_arr = []\n",
    "    eval_dict = {}\n",
    "    for j in range(0,len(p_data)):\n",
    "        Epred = p_data[j]['model'].predict(X)\n",
    "        evl_arr = evalute_preds(Y, Epred, tqids, p_data[j]['metric'])\n",
    "        eval_dict['id'] = j\n",
    "        eval_dict['features'] = X\n",
    "        eval_dict['eval'] = evl_arr\n",
    "        eval_dict_arr.append(eval_dict)\n",
    "    return eval_dict_arr\n",
    "    \n",
    "\"\"\"\n",
    "Evaluate prediction\n",
    "\"\"\"\n",
    "def evalute_preds(Y,Y_pred,Qids, met):\n",
    "    ev_arr = []\n",
    "    query_groups = pyltr.util.group.get_groups(Qids)\n",
    "    for qd, a,b in query_groups:\n",
    "        m = met.evaluate_preds(qd,Y[a:b], Y_pred[a:b] )\n",
    "        #copy the same value b-a times\n",
    "        ev_arr.extend([m]*(b-a))\n",
    "    return  ev_arr\n",
    "\n",
    "\"\"\"\n",
    "Group data inside a cluster based on ids as ids needs to be  contiguous.\n",
    "It may happen that after clustering the tids are not contigous then LambdaMart will throw error\n",
    "\"\"\"\n",
    "def group_tqids(p_data):\n",
    "    for j in range(0, len(p_data)):\n",
    "        aa = p_data[j]['data']\n",
    "        bb = p_data[j]['label']\n",
    "        cc = p_data[j]['tqid']\n",
    "        ord_data = sort_together([cc,aa.flatten(),bb])\n",
    "        p_data[j]['data'] = np.array([[np.array(d)] for d in ord_data[1]])\n",
    "        p_data[j]['label'] = np.array(ord_data[2])\n",
    "        p_data[j]['tqid'] = np.array(ord_data[0])\n",
    "    return p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MQ2007/Fold1/train.txt') as trainfile, \\\n",
    "         open('./MQ2007/Fold1/vali.txt') as valifile, \\\n",
    "         open('./MQ2007/Fold1/test.txt') as evalfile:\n",
    "    TX, Ty, Tqids, _ = pyltr.data.letor.read_dataset(trainfile)\n",
    "    VX, Vy, Vqids, _ = pyltr.data.letor.read_dataset(valifile)\n",
    "    EX, Ey, Eqids, _ = pyltr.data.letor.read_dataset(evalfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Base Line model on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1600        2.54m                                         \n",
      "    2       0.1986        2.77m                                         \n",
      "    3       0.2943        2.78m                                         \n",
      "    4       0.3486        2.79m                                         \n",
      "    5       0.3530        2.80m                                         \n",
      "    6       0.3555        2.81m                                         \n",
      "    7       0.3613        2.89m                                         \n",
      "    8       0.3678        2.87m                                         \n",
      "    9       0.3696        2.86m                                         \n",
      "   10       0.3730        2.85m                                         \n",
      "   15       0.3894        2.79m                                         \n",
      "   20       0.4031        2.71m                                         \n",
      "   25       0.4104        2.64m                                         \n",
      "   30       0.4181        2.58m                                         \n",
      "   35       0.4228        2.50m                                         \n",
      "   40       0.4280        2.43m                                         \n",
      "   45       0.4322        2.35m                                         \n",
      "   50       0.4371        2.28m                                         \n",
      "   60       0.4452        2.13m                                         \n",
      "   70       0.4506        1.98m                                         \n",
      "   80       0.4541        1.83m                                         \n",
      "   90       0.4600        1.68m                                         \n",
      "  100       0.4635        1.53m                                         \n",
      "  120       0.4712        1.22m                                         \n",
      "  140       0.4799       54.91s                                         \n",
      "  160       0.4882       36.64s                                         \n",
      "  180       0.4933       18.33s                                         \n",
      "  200       0.5009        0.00s                                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyltr.models.lambdamart.LambdaMART at 0x1a1f9d5050>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_metric = pyltr.metrics.NDCG(k=5)\n",
    "    \n",
    "base_model = pyltr.models.LambdaMART(\n",
    "            metric=base_metric,\n",
    "            n_estimators=200,\n",
    "            verbose=1,\n",
    ")\n",
    "\n",
    "base_model.fit(TX,Ty, Tqids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1, take the average of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 1min 16s, total: 2min 19s\n",
      "Wall time: 5min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 3, 2, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "##Step 1\n",
    "## compute the average of the feature\n",
    "f_avg = np.array([[np.mean(subarray)] for subarray in TX])\n",
    "##cluster the feature into 5 clusters as stated in the research paper\n",
    "clustering = AgglomerativeClustering(n_clusters=4).fit(f_avg)\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model on each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1534       54.10s                                         \n",
      "    2       0.1592       49.80s                                         \n",
      "    3       0.1713       48.67s                                         \n",
      "    4       0.1792       47.72s                                         \n",
      "    5       0.1976       47.20s                                         \n",
      "    6       0.2016       46.73s                                         \n",
      "    7       0.2024       46.15s                                         \n",
      "    8       0.2022       45.22s                                         \n",
      "    9       0.2070       44.76s                                         \n",
      "   10       0.2070       44.19s                                         \n",
      "   15       0.2084       42.65s                                         \n",
      "   20       0.2139       41.98s                                         \n",
      "   25       0.2155       41.58s                                         \n",
      "   30       0.2183       40.66s                                         \n",
      "   35       0.2210       39.91s                                         \n",
      "   40       0.2223       39.33s                                         \n",
      "   45       0.2288       38.78s                                         \n",
      "   50       0.2314       38.21s                                         \n",
      "   60       0.2336       37.34s                                         \n",
      "   70       0.2377       36.44s                                         \n",
      "   80       0.2399       35.56s                                         \n",
      "   90       0.2417       34.48s                                         \n",
      "  100       0.2431       33.80s                                         \n",
      "  120       0.2473       31.90s                                         \n",
      "  140       0.2504       30.03s                                         \n",
      "  160       0.2543       28.30s                                         \n",
      "  180       0.2557       26.73s                                         \n",
      "  200       0.2587       25.02s                                         \n",
      "  220       0.2612       23.30s                                         \n",
      "  240       0.2645       21.72s                                         \n",
      "  260       0.2681       20.01s                                         \n",
      "  280       0.2690       18.31s                                         \n",
      "  300       0.2713       16.73s                                         \n",
      "  320       0.2724       15.11s                                         \n",
      "  340       0.2741       13.49s                                         \n",
      "  360       0.2758       11.84s                                         \n",
      "  380       0.2779       10.19s                                         \n",
      "  400       0.2802        8.49s                                         \n",
      "  420       0.2818        6.81s                                         \n",
      "  440       0.2844        5.12s                                         \n",
      "  460       0.2878        3.41s                                         \n",
      "  480       0.2889        1.70s                                         \n",
      "  500       0.2902        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.2915        1.52m                                         \n",
      "    2       0.2949        1.45m                                         \n",
      "    3       0.2996        1.42m                                         \n",
      "    4       0.2996        1.40m                                         \n",
      "    5       0.2969        1.39m                                         \n",
      "    6       0.3026        1.38m                                         \n",
      "    7       0.3047        1.38m                                         \n",
      "    8       0.3083        1.37m                                         \n",
      "    9       0.3111        1.37m                                         \n",
      "   10       0.3132        1.37m                                         \n",
      "   15       0.3134        1.37m                                         \n",
      "   20       0.3463        1.39m                                         \n",
      "   25       0.3567        1.37m                                         \n",
      "   30       0.3607        1.35m                                         \n",
      "   35       0.3645        1.33m                                         \n",
      "   40       0.3845        1.31m                                         \n",
      "   45       0.3900        1.30m                                         \n",
      "   50       0.3988        1.28m                                         \n",
      "   60       0.4129        1.25m                                         \n",
      "   70       0.4137        1.22m                                         \n",
      "   80       0.4272        1.19m                                         \n",
      "   90       0.4293        1.16m                                         \n",
      "  100       0.4329        1.13m                                         \n",
      "  120       0.4427        1.07m                                         \n",
      "  140       0.4455        1.02m                                         \n",
      "  160       0.4471       57.58s                                         \n",
      "  180       0.4514       54.17s                                         \n",
      "  200       0.4534       50.81s                                         \n",
      "  220       0.4592       47.39s                                         \n",
      "  240       0.4612       43.94s                                         \n",
      "  260       0.4660       40.54s                                         \n",
      "  280       0.4692       37.15s                                         \n",
      "  300       0.4727       33.75s                                         \n",
      "  320       0.4750       30.37s                                         \n",
      "  340       0.4760       26.99s                                         \n",
      "  360       0.4801       23.61s                                         \n",
      "  380       0.4843       20.22s                                         \n",
      "  400       0.4862       16.85s                                         \n",
      "  420       0.4869       13.47s                                         \n",
      "  440       0.4890       10.10s                                         \n",
      "  460       0.4939        6.73s                                         \n",
      "  480       0.4990        3.36s                                         \n",
      "  500       0.5030        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1601        1.35m                                         \n",
      "    2       0.2658        1.31m                                         \n",
      "    3       0.2681        1.27m                                         \n",
      "    4       0.2484        1.27m                                         \n",
      "    5       0.2856        1.25m                                         \n",
      "    6       0.2868        1.24m                                         \n",
      "    7       0.2552        1.24m                                         \n",
      "    8       0.2900        1.24m                                         \n",
      "    9       0.2904        1.23m                                         \n",
      "   10       0.2579        1.23m                                         \n",
      "   15       0.3251        1.21m                                         \n",
      "   20       0.3361        1.19m                                         \n",
      "   25       0.3377        1.17m                                         \n",
      "   30       0.3419        1.16m                                         \n",
      "   35       0.3420        1.15m                                         \n",
      "   40       0.3446        1.14m                                         \n",
      "   45       0.3494        1.12m                                         \n",
      "   50       0.3505        1.11m                                         \n",
      "   60       0.3577        1.09m                                         \n",
      "   70       0.3726        1.07m                                         \n",
      "   80       0.3744        1.04m                                         \n",
      "   90       0.3779        1.02m                                         \n",
      "  100       0.3924       59.47s                                         \n",
      "  120       0.3991       56.57s                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  140       0.4044       53.63s                                         \n",
      "  160       0.4136       50.79s                                         \n",
      "  180       0.4172       47.81s                                         \n",
      "  200       0.4218       44.83s                                         \n",
      "  220       0.4331       41.83s                                         \n",
      "  240       0.4373       38.84s                                         \n",
      "  260       0.4418       35.83s                                         \n",
      "  280       0.4437       32.84s                                         \n",
      "  300       0.4497       29.84s                                         \n",
      "  320       0.4528       26.86s                                         \n",
      "  340       0.4580       23.87s                                         \n",
      "  360       0.4591       20.88s                                         \n",
      "  380       0.4648       17.89s                                         \n",
      "  400       0.4703       14.91s                                         \n",
      "  420       0.4728       11.93s                                         \n",
      "  440       0.4764        8.95s                                         \n",
      "  460       0.4807        5.97s                                         \n",
      "  480       0.4851        2.99s                                         \n",
      "  500       0.4897        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1068        1.77m                                         \n",
      "    2       0.1649        1.70m                                         \n",
      "    3       0.1783        1.70m                                         \n",
      "    4       0.1208        1.68m                                         \n",
      "    5       0.1788        1.67m                                         \n",
      "    6       0.1463        1.66m                                         \n",
      "    7       0.1891        1.66m                                         \n",
      "    8       0.1959        1.66m                                         \n",
      "    9       0.2444        1.65m                                         \n",
      "   10       0.2698        1.65m                                         \n",
      "   15       0.2932        1.63m                                         \n",
      "   20       0.2983        1.61m                                         \n",
      "   25       0.3039        1.60m                                         \n",
      "   30       0.3090        1.58m                                         \n",
      "   35       0.3120        1.56m                                         \n",
      "   40       0.3149        1.55m                                         \n",
      "   45       0.3183        1.53m                                         \n",
      "   50       0.3286        1.52m                                         \n",
      "   60       0.3347        1.49m                                         \n",
      "   70       0.3411        1.45m                                         \n",
      "   80       0.3473        1.42m                                         \n",
      "   90       0.3495        1.38m                                         \n",
      "  100       0.3510        1.35m                                         \n",
      "  120       0.3590        1.28m                                         \n",
      "  140       0.3732        1.22m                                         \n",
      "  160       0.3775        1.16m                                         \n",
      "  180       0.3842        1.09m                                         \n",
      "  200       0.3901        1.02m                                         \n",
      "  220       0.3940       57.21s                                         \n",
      "  240       0.3972       53.22s                                         \n",
      "  260       0.4007       49.27s                                         \n",
      "  280       0.4023       45.16s                                         \n",
      "  300       0.4078       41.10s                                         \n",
      "  320       0.4095       37.06s                                         \n",
      "  340       0.4148       32.93s                                         \n",
      "  360       0.4194       28.82s                                         \n",
      "  380       0.4241       24.70s                                         \n",
      "  400       0.4309       20.58s                                         \n",
      "  420       0.4350       16.46s                                         \n",
      "  440       0.4379       12.35s                                         \n",
      "  460       0.4424        8.24s                                         \n",
      "  480       0.4458        4.13s                                         \n",
      "  500       0.4476        0.00s                                         \n"
     ]
    }
   ],
   "source": [
    "## Arrange the data cluster wise\n",
    "partitioned_data = partition_data_cluster_wise(f_avg,Ty,Tqids,clustering.labels_)\n",
    "##train model for each cluster\n",
    "partitioned_data = train_model_using_LambdaMART(partitioned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate partitioned data and create new features set based in the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate partiotioned data\n",
    "partitioned_data = evaluate_partitioned_data(partitioned_data)\n",
    "##merge partitioned data as mentioned in the paper [q11,q12, ..q1n, q21,q22, ...., q41,...]\n",
    "merg_data = concatenate_cluster_eval(partitioned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 cluster data on new feature set created from evaluation and train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=4).fit(merg_data['data'])\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.0868        1.15m                                         \n",
      "    2       0.0920        1.11m                                         \n",
      "    3       0.0926        1.09m                                         \n",
      "    4       0.0910        1.10m                                         \n",
      "    5       0.0907        1.10m                                         \n",
      "    6       0.0940        1.09m                                         \n",
      "    7       0.0885        1.09m                                         \n",
      "    8       0.0929        1.09m                                         \n",
      "    9       0.0933        1.08m                                         \n",
      "   10       0.0973        1.08m                                         \n",
      "   15       0.0957        1.07m                                         \n",
      "   20       0.0990        1.06m                                         \n",
      "   25       0.0986        1.04m                                         \n",
      "   30       0.0996        1.03m                                         \n",
      "   35       0.0989        1.02m                                         \n",
      "   40       0.1010        1.01m                                         \n",
      "   45       0.0969        1.00m                                         \n",
      "   50       0.0968       59.51s                                         \n",
      "   60       0.0970       57.98s                                         \n",
      "   70       0.0958       56.74s                                         \n",
      "   80       0.0962       55.35s                                         \n",
      "   90       0.0954       54.03s                                         \n",
      "  100       0.0976       52.83s                                         \n",
      "  120       0.0991       50.19s                                         \n",
      "  140       0.0977       47.57s                                         \n",
      "  160       0.0965       44.87s                                         \n",
      "  180       0.0951       42.23s                                         \n",
      "  200       0.0968       39.63s                                         \n",
      "  220       0.0995       37.16s                                         \n",
      "  240       0.0994       34.54s                                         \n",
      "  260       0.0977       31.87s                                         \n",
      "  280       0.0966       29.22s                                         \n",
      "  300       0.0976       26.56s                                         \n",
      "  320       0.0976       23.96s                                         \n",
      "  340       0.0983       21.48s                                         \n",
      "  360       0.0975       18.90s                                         \n",
      "  380       0.0978       16.34s                                         \n",
      "  400       0.0972       13.69s                                         \n",
      "  420       0.0967       11.00s                                         \n",
      "  440       0.0989        8.25s                                         \n",
      "  460       0.0997        5.51s                                         \n",
      "  480       0.0967        2.76s                                         \n",
      "  500       0.0955        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1512        1.97m                                         \n",
      "    2       0.1649        1.89m                                         \n",
      "    3       0.1661        1.87m                                         \n",
      "    4       0.1592        1.87m                                         \n",
      "    5       0.1692        1.87m                                         \n",
      "    6       0.1650        1.85m                                         \n",
      "    7       0.1695        1.85m                                         \n",
      "    8       0.1662        1.84m                                         \n",
      "    9       0.1700        1.84m                                         \n",
      "   10       0.1603        1.83m                                         \n",
      "   15       0.1704        1.80m                                         \n",
      "   20       0.1719        1.78m                                         \n",
      "   25       0.1670        1.75m                                         \n",
      "   30       0.1633        1.73m                                         \n",
      "   35       0.1700        1.71m                                         \n",
      "   40       0.1636        1.69m                                         \n",
      "   45       0.1673        1.67m                                         \n",
      "   50       0.1656        1.65m                                         \n",
      "   60       0.1747        1.61m                                         \n",
      "   70       0.1626        1.57m                                         \n",
      "   80       0.1650        1.53m                                         \n",
      "   90       0.1602        1.50m                                         \n",
      "  100       0.1657        1.46m                                         \n",
      "  120       0.1632        1.38m                                         \n",
      "  140       0.1681        1.32m                                         \n",
      "  160       0.1613        1.25m                                         \n",
      "  180       0.1779        1.18m                                         \n",
      "  200       0.1768        1.11m                                         \n",
      "  220       0.1733        1.04m                                         \n",
      "  240       0.1633       57.59s                                         \n",
      "  260       0.1603       53.08s                                         \n",
      "  280       0.1647       48.90s                                         \n",
      "  300       0.1685       44.52s                                         \n",
      "  320       0.1671       40.06s                                         \n",
      "  340       0.1683       35.59s                                         \n",
      "  360       0.1637       31.14s                                         \n",
      "  380       0.1661       26.68s                                         \n",
      "  400       0.1647       22.28s                                         \n",
      "  420       0.1731       17.84s                                         \n",
      "  440       0.1693       13.38s                                         \n",
      "  460       0.1701        8.94s                                         \n",
      "  480       0.1663        4.48s                                         \n",
      "  500       0.1653        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.0000       48.44s                                         \n",
      "    2       0.0000       45.07s                                         \n",
      "    3       0.0000       44.06s                                         \n",
      "    4       0.0000       43.05s                                         \n",
      "    5       0.0000       42.68s                                         \n",
      "    6       0.0000       42.38s                                         \n",
      "    7       0.0000       42.06s                                         \n",
      "    8       0.0000       41.76s                                         \n",
      "    9       0.0000       41.55s                                         \n",
      "   10       0.0000       41.10s                                         \n",
      "   15       0.0000       38.65s                                         \n",
      "   20       0.0000       37.18s                                         \n",
      "   25       0.0000       36.02s                                         \n",
      "   30       0.0000       35.07s                                         \n",
      "   35       0.0000       34.29s                                         \n",
      "   40       0.0000       33.67s                                         \n",
      "   45       0.0000       33.12s                                         \n",
      "   50       0.0000       32.60s                                         \n",
      "   60       0.0000       31.54s                                         \n",
      "   70       0.0000       30.74s                                         \n",
      "   80       0.0000       29.92s                                         \n",
      "   90       0.0000       29.09s                                         \n",
      "  100       0.0000       28.31s                                         \n",
      "  120       0.0000       26.76s                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  140       0.0000       25.28s                                         \n",
      "  160       0.0000       23.88s                                         \n",
      "  180       0.0000       22.41s                                         \n",
      "  200       0.0000       20.98s                                         \n",
      "  220       0.0000       19.54s                                         \n",
      "  240       0.0000       18.12s                                         \n",
      "  260       0.0000       16.70s                                         \n",
      "  280       0.0000       15.29s                                         \n",
      "  300       0.0000       13.89s                                         \n",
      "  320       0.0000       12.50s                                         \n",
      "  340       0.0000       11.11s                                         \n",
      "  360       0.0000        9.71s                                         \n",
      "  380       0.0000        8.32s                                         \n",
      "  400       0.0000        6.93s                                         \n",
      "  420       0.0000        5.55s                                         \n",
      "  440       0.0000        4.16s                                         \n",
      "  460       0.0000        2.77s                                         \n",
      "  480       0.0000        1.39s                                         \n",
      "  500       0.0000        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.0338        1.10m                                         \n",
      "    2       0.0361        1.08m                                         \n",
      "    3       0.0347        1.08m                                         \n",
      "    4       0.0356        1.09m                                         \n",
      "    5       0.0343        1.09m                                         \n",
      "    6       0.0368        1.08m                                         \n",
      "    7       0.0357        1.08m                                         \n",
      "    8       0.0369        1.09m                                         \n",
      "    9       0.0375        1.09m                                         \n",
      "   10       0.0364        1.09m                                         \n",
      "   15       0.0380        1.09m                                         \n",
      "   20       0.0375        1.07m                                         \n",
      "   25       0.0390        1.06m                                         \n",
      "   30       0.0375        1.04m                                         \n",
      "   35       0.0396        1.03m                                         \n",
      "   40       0.0390        1.02m                                         \n",
      "   45       0.0398        1.01m                                         \n",
      "   50       0.0378        1.00m                                         \n",
      "   60       0.0386       58.63s                                         \n",
      "   70       0.0376       57.31s                                         \n",
      "   80       0.0391       55.85s                                         \n",
      "   90       0.0398       54.28s                                         \n",
      "  100       0.0393       52.77s                                         \n",
      "  120       0.0390       49.87s                                         \n",
      "  140       0.0392       47.11s                                         \n",
      "  160       0.0383       44.35s                                         \n",
      "  180       0.0387       41.66s                                         \n",
      "  200       0.0385       39.06s                                         \n",
      "  220       0.0394       36.69s                                         \n",
      "  240       0.0391       34.16s                                         \n",
      "  260       0.0394       31.66s                                         \n",
      "  280       0.0382       29.10s                                         \n",
      "  300       0.0389       26.47s                                         \n",
      "  320       0.0372       23.78s                                         \n",
      "  340       0.0385       21.10s                                         \n",
      "  360       0.0382       18.44s                                         \n",
      "  380       0.0383       15.78s                                         \n",
      "  400       0.0381       13.13s                                         \n",
      "  420       0.0385       10.49s                                         \n",
      "  440       0.0379        7.86s                                         \n",
      "  460       0.0377        5.23s                                         \n",
      "  480       0.0374        2.61s                                         \n",
      "  500       0.0383        0.00s                                         \n"
     ]
    }
   ],
   "source": [
    "partitioned_data = partition_data_cluster_wise(merg_data['data'],merg_data['label'],merg_data['tqid'],clustering.labels_)\n",
    "##group the ids as it needs to be contogous\n",
    "partitioned_data = group_tqids(partitioned_data)\n",
    "##train model again on this dataset\n",
    "partitioned_data = train_model_using_LambdaMART(partitioned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate partitioned data and create new feature set based in second clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate partiotioned data\n",
    "partitioned_data = evaluate_partitioned_data(partitioned_data)\n",
    "##merge partitioned data as mentioned in the paper [q11,q12, ..q1n, q21,q22, ...., q41,...]\n",
    "merg_data = concatenate_cluster_eval(partitioned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 cluster data for the last time  on new feature set created from evaluation and train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.0000        3.81m                                         \n",
      "    2       0.0000        3.70m                                         \n",
      "    3       0.0000        3.67m                                         \n",
      "    4       0.0000        3.62m                                         \n",
      "    5       0.0000        3.61m                                         \n",
      "    6       0.0000        3.59m                                         \n",
      "    7       0.0000        3.59m                                         \n",
      "    8       0.0000        3.57m                                         \n",
      "    9       0.0000        3.56m                                         \n",
      "   10       0.0000        3.54m                                         \n",
      "   15       0.0000        3.48m                                         \n",
      "   20       0.0000        3.43m                                         \n",
      "   25       0.0000        3.39m                                         \n",
      "   30       0.0000        3.36m                                         \n",
      "   35       0.0000        3.32m                                         \n",
      "   40       0.0000        3.28m                                         \n",
      "   45       0.0000        3.24m                                         \n",
      "   50       0.0000        3.20m                                         \n",
      "   60       0.0000        3.13m                                         \n",
      "   70       0.0000        3.05m                                         \n",
      "   80       0.0000        3.00m                                         \n",
      "   90       0.0000        2.94m                                         \n",
      "  100       0.0000        2.86m                                         \n",
      "  120       0.0000        2.72m                                         \n",
      "  140       0.0000        2.59m                                         \n",
      "  160       0.0000        2.44m                                         \n",
      "  180       0.0000        2.31m                                         \n",
      "  200       0.0000        2.18m                                         \n",
      "  220       0.0000        2.03m                                         \n",
      "  240       0.0000        1.88m                                         \n",
      "  260       0.0000        1.73m                                         \n",
      "  280       0.0000        1.58m                                         \n",
      "  300       0.0000        1.44m                                         \n",
      "  320       0.0000        1.29m                                         \n",
      "  340       0.0000        1.15m                                         \n",
      "  360       0.0000        1.00m                                         \n",
      "  380       0.0000       51.56s                                         \n",
      "  400       0.0000       42.92s                                         \n",
      "  420       0.0000       34.31s                                         \n",
      "  440       0.0000       25.71s                                         \n",
      "  460       0.0000       17.13s                                         \n",
      "  480       0.0000        8.56s                                         \n",
      "  500       0.0000        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.0749       46.17s                                         \n",
      "    2       0.0781       46.46s                                         \n",
      "    3       0.0783       46.19s                                         \n",
      "    4       0.0790       47.08s                                         \n",
      "    5       0.0802       46.66s                                         \n",
      "    6       0.0794       46.19s                                         \n",
      "    7       0.0796       46.15s                                         \n",
      "    8       0.0809       45.98s                                         \n",
      "    9       0.0802       45.76s                                         \n",
      "   10       0.0804       45.81s                                         \n",
      "   15       0.0804       45.01s                                         \n",
      "   20       0.0817       44.50s                                         \n",
      "   25       0.0807       43.99s                                         \n",
      "   30       0.0815       43.54s                                         \n",
      "   35       0.0813       43.03s                                         \n",
      "   40       0.0823       42.54s                                         \n",
      "   45       0.0806       42.00s                                         \n",
      "   50       0.0815       41.53s                                         \n",
      "   60       0.0829       40.56s                                         \n",
      "   70       0.0815       39.58s                                         \n",
      "   80       0.0817       38.63s                                         \n",
      "   90       0.0811       37.68s                                         \n",
      "  100       0.0818       36.76s                                         \n",
      "  120       0.0824       34.90s                                         \n",
      "  140       0.0812       33.07s                                         \n",
      "  160       0.0806       31.19s                                         \n",
      "  180       0.0818       29.33s                                         \n",
      "  200       0.0805       27.48s                                         \n",
      "  220       0.0811       25.63s                                         \n",
      "  240       0.0815       23.84s                                         \n",
      "  260       0.0798       22.01s                                         \n",
      "  280       0.0809       20.17s                                         \n",
      "  300       0.0825       18.32s                                         \n",
      "  320       0.0817       16.49s                                         \n",
      "  340       0.0807       14.65s                                         \n",
      "  360       0.0810       12.82s                                         \n",
      "  380       0.0806       10.98s                                         \n",
      "  400       0.0819        9.15s                                         \n",
      "  420       0.0808        7.32s                                         \n",
      "  440       0.0814        5.49s                                         \n",
      "  460       0.0810        3.66s                                         \n",
      "  480       0.0823        1.83s                                         \n",
      "  500       0.0805        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.6158        7.84s                                         \n",
      "    2       0.6158        7.48s                                         \n",
      "    3       0.6158        7.68s                                         \n",
      "    4       0.6158        7.62s                                         \n",
      "    5       0.6158        7.54s                                         \n",
      "    6       0.6158        7.50s                                         \n",
      "    7       0.6158        7.50s                                         \n",
      "    8       0.6158        7.50s                                         \n",
      "    9       0.6158        7.45s                                         \n",
      "   10       0.6158        7.41s                                         \n",
      "   15       0.6158        7.33s                                         \n",
      "   20       0.6158        7.27s                                         \n",
      "   25       0.6158        7.14s                                         \n",
      "   30       0.6158        7.12s                                         \n",
      "   35       0.6158        7.07s                                         \n",
      "   40       0.6158        6.98s                                         \n",
      "   45       0.6158        6.87s                                         \n",
      "   50       0.6158        6.80s                                         \n",
      "   60       0.6158        6.65s                                         \n",
      "   70       0.6158        6.58s                                         \n",
      "   80       0.6158        6.43s                                         \n",
      "   90       0.6158        6.25s                                         \n",
      "  100       0.6158        6.11s                                         \n",
      "  120       0.6158        5.77s                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  140       0.6158        5.46s                                         \n",
      "  160       0.6158        5.14s                                         \n",
      "  180       0.6158        4.83s                                         \n",
      "  200       0.6158        4.52s                                         \n",
      "  220       0.6158        4.20s                                         \n",
      "  240       0.6158        3.90s                                         \n",
      "  260       0.6158        3.60s                                         \n",
      "  280       0.6158        3.30s                                         \n",
      "  300       0.6158        3.01s                                         \n",
      "  320       0.6158        2.73s                                         \n",
      "  340       0.6158        2.46s                                         \n",
      "  360       0.6158        2.15s                                         \n",
      "  380       0.6158        1.84s                                         \n",
      "  400       0.6158        1.54s                                         \n",
      "  420       0.6158        1.24s                                         \n",
      "  440       0.6158        0.93s                                         \n",
      "  460       0.6158        0.62s                                         \n",
      "  480       0.6158        0.31s                                         \n",
      "  500       0.6158        0.00s                                         \n",
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.3321       20.90s                                         \n",
      "    2       0.3428       20.54s                                         \n",
      "    3       0.3381       20.14s                                         \n",
      "    4       0.3428       19.85s                                         \n",
      "    5       0.3381       20.29s                                         \n",
      "    6       0.3428       20.43s                                         \n",
      "    7       0.3381       20.33s                                         \n",
      "    8       0.3428       20.17s                                         \n",
      "    9       0.3381       20.13s                                         \n",
      "   10       0.3428       19.95s                                         \n",
      "   15       0.3423       19.62s                                         \n",
      "   20       0.3434       19.50s                                         \n",
      "   25       0.3400       19.16s                                         \n",
      "   30       0.3423       18.94s                                         \n",
      "   35       0.3423       18.67s                                         \n",
      "   40       0.3423       18.46s                                         \n",
      "   45       0.3423       18.22s                                         \n",
      "   50       0.3452       17.88s                                         \n",
      "   60       0.3412       17.49s                                         \n",
      "   70       0.3412       17.07s                                         \n",
      "   80       0.3441       16.75s                                         \n",
      "   90       0.3412       16.38s                                         \n",
      "  100       0.3412       15.96s                                         \n",
      "  120       0.3412       15.11s                                         \n",
      "  140       0.3412       14.31s                                         \n",
      "  160       0.3412       13.47s                                         \n",
      "  180       0.3412       12.64s                                         \n",
      "  200       0.3441       11.82s                                         \n",
      "  220       0.3423       11.07s                                         \n",
      "  240       0.3412       10.27s                                         \n",
      "  260       0.3412        9.53s                                         \n",
      "  280       0.3423        8.74s                                         \n",
      "  300       0.3412        7.95s                                         \n",
      "  320       0.3452        7.15s                                         \n",
      "  340       0.3441        6.34s                                         \n",
      "  360       0.3423        5.53s                                         \n",
      "  380       0.3441        4.72s                                         \n",
      "  400       0.3412        3.92s                                         \n",
      "  420       0.3412        3.13s                                         \n",
      "  440       0.3412        2.34s                                         \n",
      "  460       0.3441        1.56s                                         \n",
      "  480       0.3412        0.78s                                         \n",
      "  500       0.3412        0.00s                                         \n"
     ]
    }
   ],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=4).fit(merg_data['data'])\n",
    "clustering.labels_\n",
    "partitioned_data = partition_data_cluster_wise(merg_data['data'],merg_data['label'],merg_data['tqid'],clustering.labels_)\n",
    "##group the ids as it needs to be contogous\n",
    "partitioned_data= group_tqids(partitioned_data)\n",
    "##train model again on this dataset\n",
    "partitioned_data = train_model_using_LambdaMART(partitioned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate partiotioned data\n",
    "partitioned_data = evaluate_partitioned_data(partitioned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for cluster classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = evaluate_features(partitioned_data, TX,Ty, Tqids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(xxx[4]['eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random ranking: 341443188670396.94\n",
      "Our model: 5333387515706.951\n",
      "Random ranking: 0.23600386783826527\n",
      "Our model: 0.20345739558503712\n",
      "Random ranking: 0.25241019519320473\n",
      "Our model: 0.007937142931938607\n",
      "Random ranking: 0.2600063674729722\n",
      "Our model: 0.22840703608300203\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,4):\n",
    "    f_avg = np.array([[np.mean(subarray)] for subarray in TX])\n",
    "    Epred = partitioned_data[k]['model'].predict(f_avg)\n",
    "    print ('Random ranking:',  partitioned_data[k]['metric'].calc_mean_random(Tqids, Ty))\n",
    "    print ('Our model:', partitioned_data[k]['metric'].calc_mean(Tqids, Ty, Epred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
